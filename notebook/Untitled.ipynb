{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18(pretrained=True)# 加载模型\n",
    "optimizer = torch.optim.SGD(params=[\n",
    "    {'params': model.layer2.parameters()},\n",
    "    {'params': model.layer3.parameters(), 'lr':0.2},\n",
    "], lr=0.1)\t# base_lr = 0.1\n",
    "\n",
    "# 设置warm up的轮次为100次\n",
    "warm_up_iter = 10\n",
    "T_max = 50\t# 周期\n",
    "lr_max = 0.1\t# 最大值\n",
    "lr_min = 1e-5\t# 最小值\n",
    "\n",
    "# 为param_groups[0] (即model.layer2) 设置学习率调整规则 - Warm up + Cosine Anneal\n",
    "lambda0 = lambda cur_iter: cur_iter / warm_up_iter if  cur_iter < warm_up_iter else \\\n",
    "        (lr_min + 0.5*(lr_max-lr_min)*(1.0+math.cos( (cur_iter-warm_up_iter)/(T_max-warm_up_iter)*math.pi)))/0.1\n",
    "\n",
    "#  param_groups[1] 不进行调整\n",
    "lambda1 = lambda cur_iter: 1\n",
    "\n",
    "# LambdaLR\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda0, lambda1])\n",
    "\n",
    "for epoch in range(50):\n",
    "    print(optimizer.param_groups[0]['lr'], optimizer.param_groups[1]['lr'])\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12.1",
   "language": "python",
   "name": "torch1.12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
