{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b4d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from datasets import load_dataset \n",
    "\n",
    "import os \n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pyarrow\n",
    "import time \n",
    "import json \n",
    "\n",
    "import sys \n",
    "sys.path.append('../code')\n",
    "import utils\n",
    "import model \n",
    "import loss \n",
    "from custom_dataset import CustomDataset\n",
    "import train_v1 as train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cea2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390a1a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33524\n",
      "33526\n",
      "33524\n",
      "33525\n"
     ]
    }
   ],
   "source": [
    "(gene_dict, dataset_gene, dataset_gene_ids) = utils.generate_gene_dic()\n",
    "\n",
    "tokenizer = utils.tokenizer_v1(gene_dict= gene_dict,\n",
    "                         dataset_gene= dataset_gene,\n",
    "                         dataset_gene_ids= dataset_gene_ids) \n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(vocab_size)\n",
    "\n",
    "tokenizer.add_token(token = '<cls>')\n",
    "tokenizer.add_token(token = '<pad>')\n",
    "#tokenizer.gene_dict['<cls>'] = vocab_size\n",
    "print(tokenizer.vocab_size)\n",
    "print(tokenizer.gene_dict['<cls>']) \n",
    "print(tokenizer.gene_dict['<pad>']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eeae40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collate_fn = utils.collater(tokenizer= tokenizer, max_expression= 100, mask_ratio = 0.1, \n",
    "                            max_num = 2000,  rho = 0.1, pad_idx = tokenizer.gene_dict['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd67a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2cb725fa684a0b8ba8612a705482d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1b8e5fb402422ba4f57ed7ae425d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunrui/anaconda3/envs/pytorch/lib/python3.10/site-packages/datasets/table.py:1392: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e12cbffa642438c9225a2fd046ad976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/419 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f1c4ce417346e2aec1ff9bfa636f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#dataset_1  = load_dataset(path = 'mus_brain', cache_dir = 'huggingface_cache')\n",
    "dataset_1 = load_dataset(path = '/work/sunrui/pretrain_dataset/allen_2021_data',\n",
    "                     cache_dir = '/work/sunrui/huggingface')\n",
    "dataset_2 = load_dataset(path = '/work/sunrui/pretrain_dataset/allen_2023_data', \n",
    "                     cache_dir = '/work/sunrui/huggingface') \n",
    "\n",
    "dataset_1 = dataset_1['train'].select(range(3000)).train_test_split(test_size = 0.05)\n",
    "dataset_2= dataset_2['train'].select(range(3000)).train_test_split(test_size = 0.05)\n",
    "\n",
    "#dataset_1 = dataset_1['train'].train_test_split(test_size = 0.05)\n",
    "#dataset_2= dataset_2['train'].train_test_split(test_size = 0.05)\n",
    "\n",
    "train_dataset_1, test_dataset_1 = dataset_1['train'], dataset_2['test']\n",
    "train_dataset_2, test_dataset_2 = dataset_2['train'], dataset_2['test']\n",
    "\n",
    "train_dataset = CustomDataset([train_dataset_1, train_dataset_2]) \n",
    "test_dataset = CustomDataset([test_dataset_1, test_dataset_2]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2b9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_embedding_num = 104\n",
    "gene_embedding_num = tokenizer.vocab_size\n",
    "\n",
    "d_model = 256\n",
    "gene_padding_idx = tokenizer.gene_dict['<pad>']\n",
    "count_padding_idx = 103\n",
    "n_head = 8\n",
    "dim_ffn = 4*d_model\n",
    "dropout = 0.1\n",
    "layer_norm_eps =1e-5\n",
    "batch_first = True\n",
    "norm_first = False\n",
    "num_layers = 4\n",
    "norm = None\n",
    "num_hiddens = 256\n",
    "\n",
    "my_model = model.sc_pretrain(count_embedding_num,\n",
    "                 gene_embedding_num,\n",
    "                 d_model,\n",
    "                 gene_padding_idx,\n",
    "                 count_padding_idx,\n",
    "                 n_head,\n",
    "                 dim_ffn,\n",
    "                 dropout,\n",
    "                 layer_norm_eps,\n",
    "                 batch_first,\n",
    "                 norm_first,\n",
    "                 num_layers,\n",
    "                 norm,\n",
    "                 num_hiddens) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3916ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建 DataLoader 实例\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn= collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn= collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93a0e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0 begin:================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/sunrui/pretrain_project/notebook/../code/utils.py:174: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1678411187366/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  batch_data['counts_0'] = torch.tensor(batch_data['counts_0'], dtype = torch.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss: 6.6520, Exp_loss : 4.6722, Clip_loss ; 1.9798\n",
      "Step 2, Loss: 6.3365, Exp_loss : 4.4048, Clip_loss ; 1.9317\n",
      "Step 3, Loss: 6.0938, Exp_loss : 4.1683, Clip_loss ; 1.9256\n",
      "Step 4, Loss: 5.8609, Exp_loss : 3.9679, Clip_loss ; 1.8930\n",
      "Step 5, Loss: 5.5725, Exp_loss : 3.7774, Clip_loss ; 1.7951\n",
      "Step 6, Loss: 5.3786, Exp_loss : 3.6483, Clip_loss ; 1.7303\n",
      "Step 7, Loss: 5.2578, Exp_loss : 3.5547, Clip_loss ; 1.7032\n",
      "Step 8, Loss: 5.0828, Exp_loss : 3.4517, Clip_loss ; 1.6311\n",
      "Step 9, Loss: 4.9553, Exp_loss : 3.3990, Clip_loss ; 1.5564\n",
      "Step 10, Loss: 4.8056, Exp_loss : 3.3351, Clip_loss ; 1.4706\n",
      "Step 11, Loss: 4.6533, Exp_loss : 3.2768, Clip_loss ; 1.3764\n",
      "Step 12, Loss: 4.5233, Exp_loss : 3.2559, Clip_loss ; 1.2674\n",
      "Step 13, Loss: 4.5071, Exp_loss : 3.1847, Clip_loss ; 1.3225\n",
      "Step 14, Loss: 4.4165, Exp_loss : 3.1789, Clip_loss ; 1.2376\n",
      "Step 15, Loss: 4.4342, Exp_loss : 3.1412, Clip_loss ; 1.2931\n",
      "Step 16, Loss: 4.3070, Exp_loss : 3.0387, Clip_loss ; 1.2683\n",
      "Step 17, Loss: 4.2755, Exp_loss : 3.0784, Clip_loss ; 1.1971\n",
      "Step 18, Loss: 4.2170, Exp_loss : 3.0478, Clip_loss ; 1.1692\n",
      "Step 19, Loss: 4.1508, Exp_loss : 3.0150, Clip_loss ; 1.1358\n",
      "Step 20, Loss: 4.1494, Exp_loss : 3.0168, Clip_loss ; 1.1326\n",
      "Step 21, Loss: 4.0915, Exp_loss : 2.9827, Clip_loss ; 1.1088\n",
      "Step 22, Loss: 4.0024, Exp_loss : 2.9354, Clip_loss ; 1.0670\n",
      "Step 23, Loss: 4.0663, Exp_loss : 2.9343, Clip_loss ; 1.1320\n",
      "Step 24, Loss: 3.9179, Exp_loss : 2.8662, Clip_loss ; 1.0518\n",
      "Step 25, Loss: 3.9433, Exp_loss : 2.9401, Clip_loss ; 1.0032\n",
      "Step 26, Loss: 4.0138, Exp_loss : 2.9039, Clip_loss ; 1.1099\n",
      "Step 27, Loss: 3.9731, Exp_loss : 2.8859, Clip_loss ; 1.0872\n",
      "Step 28, Loss: 3.8612, Exp_loss : 2.8160, Clip_loss ; 1.0451\n",
      "Step 29, Loss: 3.8557, Exp_loss : 2.8167, Clip_loss ; 1.0390\n",
      "Step 30, Loss: 3.8455, Exp_loss : 2.7749, Clip_loss ; 1.0706\n",
      "Finished Training\n",
      "model evaluation================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunrui/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:544: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /opt/conda/conda-bld/pytorch_1678411187366/work/aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg total loss:3.7659, avg exp loss:2.8355, avg_clip_loss:0.9304\n",
      "epochs: 1 begin:================================================================================\n",
      "Step 1, Loss: 3.7774, Exp_loss : 2.8165, Clip_loss ; 0.9609\n",
      "Step 2, Loss: 3.8758, Exp_loss : 2.8283, Clip_loss ; 1.0475\n",
      "Step 3, Loss: 3.8207, Exp_loss : 2.7873, Clip_loss ; 1.0334\n",
      "Step 4, Loss: 3.8379, Exp_loss : 2.7694, Clip_loss ; 1.0685\n",
      "Step 5, Loss: 3.8010, Exp_loss : 2.7981, Clip_loss ; 1.0029\n",
      "Step 6, Loss: 3.7237, Exp_loss : 2.7408, Clip_loss ; 0.9829\n",
      "Step 7, Loss: 3.7368, Exp_loss : 2.7218, Clip_loss ; 1.0150\n",
      "Step 8, Loss: 3.6974, Exp_loss : 2.7432, Clip_loss ; 0.9542\n",
      "Step 9, Loss: 3.5855, Exp_loss : 2.6808, Clip_loss ; 0.9047\n",
      "Step 10, Loss: 3.5943, Exp_loss : 2.6627, Clip_loss ; 0.9316\n",
      "Step 11, Loss: 3.5857, Exp_loss : 2.7173, Clip_loss ; 0.8683\n",
      "Step 12, Loss: 3.6215, Exp_loss : 2.6999, Clip_loss ; 0.9216\n",
      "Step 13, Loss: 3.5969, Exp_loss : 2.6805, Clip_loss ; 0.9164\n",
      "Step 14, Loss: 3.5635, Exp_loss : 2.6711, Clip_loss ; 0.8924\n",
      "Step 15, Loss: 3.5787, Exp_loss : 2.6745, Clip_loss ; 0.9041\n",
      "Step 16, Loss: 3.5488, Exp_loss : 2.6351, Clip_loss ; 0.9136\n",
      "Step 17, Loss: 3.4772, Exp_loss : 2.6227, Clip_loss ; 0.8545\n",
      "Step 18, Loss: 3.5538, Exp_loss : 2.6494, Clip_loss ; 0.9045\n",
      "Step 19, Loss: 3.4827, Exp_loss : 2.6350, Clip_loss ; 0.8477\n",
      "Step 20, Loss: 3.5373, Exp_loss : 2.6379, Clip_loss ; 0.8994\n",
      "Step 21, Loss: 3.5626, Exp_loss : 2.6315, Clip_loss ; 0.9310\n",
      "Step 22, Loss: 3.3772, Exp_loss : 2.5439, Clip_loss ; 0.8333\n",
      "Step 23, Loss: 3.4186, Exp_loss : 2.5631, Clip_loss ; 0.8555\n",
      "Step 24, Loss: 3.5220, Exp_loss : 2.6370, Clip_loss ; 0.8849\n",
      "Step 25, Loss: 3.4235, Exp_loss : 2.6076, Clip_loss ; 0.8159\n",
      "Step 26, Loss: 3.4675, Exp_loss : 2.6240, Clip_loss ; 0.8435\n",
      "Step 27, Loss: 3.3873, Exp_loss : 2.5634, Clip_loss ; 0.8239\n",
      "Step 28, Loss: 3.3744, Exp_loss : 2.5720, Clip_loss ; 0.8024\n",
      "Step 29, Loss: 3.3680, Exp_loss : 2.5559, Clip_loss ; 0.8121\n",
      "Step 30, Loss: 3.3743, Exp_loss : 2.5729, Clip_loss ; 0.8013\n",
      "Finished Training\n",
      "model evaluation================================================================================\n",
      "avg total loss:3.3332, avg exp loss:2.6045, avg_clip_loss:0.7288\n",
      "epochs: 2 begin:================================================================================\n",
      "Step 1, Loss: 3.3555, Exp_loss : 2.6003, Clip_loss ; 0.7552\n",
      "Step 2, Loss: 3.3170, Exp_loss : 2.5522, Clip_loss ; 0.7648\n",
      "Step 3, Loss: 3.4741, Exp_loss : 2.6065, Clip_loss ; 0.8676\n",
      "Step 4, Loss: 3.3750, Exp_loss : 2.6072, Clip_loss ; 0.7678\n",
      "Step 5, Loss: 3.3616, Exp_loss : 2.5541, Clip_loss ; 0.8075\n",
      "Step 6, Loss: 3.3256, Exp_loss : 2.5028, Clip_loss ; 0.8228\n",
      "Step 7, Loss: 3.4025, Exp_loss : 2.5764, Clip_loss ; 0.8261\n",
      "Step 8, Loss: 3.3401, Exp_loss : 2.5476, Clip_loss ; 0.7925\n",
      "Step 9, Loss: 3.2715, Exp_loss : 2.5016, Clip_loss ; 0.7699\n",
      "Step 10, Loss: 3.3147, Exp_loss : 2.5615, Clip_loss ; 0.7531\n",
      "Step 11, Loss: 3.3600, Exp_loss : 2.5779, Clip_loss ; 0.7821\n",
      "Step 12, Loss: 3.2914, Exp_loss : 2.4639, Clip_loss ; 0.8274\n",
      "Step 13, Loss: 3.3439, Exp_loss : 2.5368, Clip_loss ; 0.8071\n",
      "Step 14, Loss: 3.3088, Exp_loss : 2.5094, Clip_loss ; 0.7994\n",
      "Step 15, Loss: 3.3129, Exp_loss : 2.4937, Clip_loss ; 0.8191\n",
      "Step 16, Loss: 3.2724, Exp_loss : 2.4652, Clip_loss ; 0.8072\n",
      "Step 17, Loss: 3.2461, Exp_loss : 2.5236, Clip_loss ; 0.7225\n",
      "Step 18, Loss: 3.2468, Exp_loss : 2.4864, Clip_loss ; 0.7604\n",
      "Step 19, Loss: 3.2123, Exp_loss : 2.4812, Clip_loss ; 0.7310\n",
      "Step 20, Loss: 3.1123, Exp_loss : 2.4603, Clip_loss ; 0.6520\n",
      "Step 21, Loss: 3.2671, Exp_loss : 2.4932, Clip_loss ; 0.7738\n",
      "Step 22, Loss: 3.2515, Exp_loss : 2.5154, Clip_loss ; 0.7361\n",
      "Step 23, Loss: 3.2197, Exp_loss : 2.5197, Clip_loss ; 0.6999\n",
      "Step 24, Loss: 3.3168, Exp_loss : 2.4643, Clip_loss ; 0.8526\n",
      "Step 25, Loss: 3.2447, Exp_loss : 2.5221, Clip_loss ; 0.7226\n",
      "Step 26, Loss: 3.2113, Exp_loss : 2.4781, Clip_loss ; 0.7332\n",
      "Step 27, Loss: 3.2173, Exp_loss : 2.4796, Clip_loss ; 0.7378\n",
      "Step 28, Loss: 3.1439, Exp_loss : 2.4342, Clip_loss ; 0.7098\n",
      "Step 29, Loss: 3.1581, Exp_loss : 2.4928, Clip_loss ; 0.6653\n",
      "Step 30, Loss: 3.1645, Exp_loss : 2.4409, Clip_loss ; 0.7236\n",
      "Finished Training\n",
      "model evaluation================================================================================\n",
      "avg total loss:3.1632, avg exp loss:2.5142, avg_clip_loss:0.6490\n",
      "epochs: 3 begin:================================================================================\n",
      "Step 1, Loss: 3.1759, Exp_loss : 2.4863, Clip_loss ; 0.6896\n",
      "Step 2, Loss: 3.1627, Exp_loss : 2.4663, Clip_loss ; 0.6965\n",
      "Step 3, Loss: 3.1564, Exp_loss : 2.4590, Clip_loss ; 0.6974\n",
      "Step 4, Loss: 3.1510, Exp_loss : 2.4815, Clip_loss ; 0.6695\n",
      "Step 5, Loss: 3.1305, Exp_loss : 2.4400, Clip_loss ; 0.6905\n",
      "Step 6, Loss: 3.1080, Exp_loss : 2.4286, Clip_loss ; 0.6795\n",
      "Step 7, Loss: 3.1366, Exp_loss : 2.4554, Clip_loss ; 0.6813\n",
      "Step 8, Loss: 3.1458, Exp_loss : 2.4781, Clip_loss ; 0.6677\n",
      "Step 9, Loss: 3.1615, Exp_loss : 2.4676, Clip_loss ; 0.6939\n",
      "Step 10, Loss: 3.1749, Exp_loss : 2.4777, Clip_loss ; 0.6972\n",
      "Step 11, Loss: 3.0798, Exp_loss : 2.4748, Clip_loss ; 0.6049\n",
      "Step 12, Loss: 3.1784, Exp_loss : 2.4987, Clip_loss ; 0.6797\n",
      "Step 13, Loss: 3.0731, Exp_loss : 2.4231, Clip_loss ; 0.6499\n",
      "Step 14, Loss: 3.1654, Exp_loss : 2.4456, Clip_loss ; 0.7199\n",
      "Step 15, Loss: 3.1273, Exp_loss : 2.4204, Clip_loss ; 0.7069\n",
      "Step 16, Loss: 3.0978, Exp_loss : 2.4676, Clip_loss ; 0.6301\n",
      "Step 17, Loss: 3.1299, Exp_loss : 2.4236, Clip_loss ; 0.7064\n",
      "Step 18, Loss: 3.1409, Exp_loss : 2.4345, Clip_loss ; 0.7064\n",
      "Step 19, Loss: 3.0762, Exp_loss : 2.4204, Clip_loss ; 0.6559\n",
      "Step 20, Loss: 3.0754, Exp_loss : 2.4277, Clip_loss ; 0.6477\n",
      "Step 21, Loss: 3.1027, Exp_loss : 2.4435, Clip_loss ; 0.6592\n",
      "Step 22, Loss: 3.0210, Exp_loss : 2.4224, Clip_loss ; 0.5986\n",
      "Step 23, Loss: 3.0166, Exp_loss : 2.4034, Clip_loss ; 0.6132\n",
      "Step 24, Loss: 3.0563, Exp_loss : 2.4281, Clip_loss ; 0.6282\n",
      "Step 25, Loss: 3.1609, Exp_loss : 2.4499, Clip_loss ; 0.7110\n",
      "Step 26, Loss: 3.0574, Exp_loss : 2.4417, Clip_loss ; 0.6157\n",
      "Step 27, Loss: 3.1328, Exp_loss : 2.4596, Clip_loss ; 0.6732\n",
      "Step 28, Loss: 3.1134, Exp_loss : 2.4385, Clip_loss ; 0.6748\n",
      "Step 29, Loss: 2.9936, Exp_loss : 2.4115, Clip_loss ; 0.5821\n",
      "Step 30, Loss: 2.9893, Exp_loss : 2.4211, Clip_loss ; 0.5682\n",
      "Finished Training\n",
      "model evaluation================================================================================\n",
      "avg total loss:3.0450, avg exp loss:2.4629, avg_clip_loss:0.5820\n",
      "epochs: 4 begin:================================================================================\n",
      "Step 1, Loss: 3.0250, Exp_loss : 2.4327, Clip_loss ; 0.5923\n",
      "Step 2, Loss: 3.0231, Exp_loss : 2.4134, Clip_loss ; 0.6098\n",
      "Step 3, Loss: 3.0884, Exp_loss : 2.4265, Clip_loss ; 0.6619\n",
      "Step 4, Loss: 3.0407, Exp_loss : 2.4115, Clip_loss ; 0.6292\n",
      "Step 5, Loss: 3.0167, Exp_loss : 2.4084, Clip_loss ; 0.6082\n",
      "Step 6, Loss: 3.1107, Exp_loss : 2.4469, Clip_loss ; 0.6639\n",
      "Step 7, Loss: 3.0428, Exp_loss : 2.4438, Clip_loss ; 0.5990\n",
      "Step 8, Loss: 3.0577, Exp_loss : 2.4298, Clip_loss ; 0.6278\n",
      "Step 9, Loss: 3.0408, Exp_loss : 2.4132, Clip_loss ; 0.6276\n",
      "Step 10, Loss: 3.0240, Exp_loss : 2.3986, Clip_loss ; 0.6253\n",
      "Step 11, Loss: 3.0104, Exp_loss : 2.4102, Clip_loss ; 0.6003\n",
      "Step 12, Loss: 3.0610, Exp_loss : 2.4104, Clip_loss ; 0.6507\n",
      "Step 13, Loss: 3.0449, Exp_loss : 2.4457, Clip_loss ; 0.5993\n",
      "Step 14, Loss: 2.9806, Exp_loss : 2.3980, Clip_loss ; 0.5826\n",
      "Step 15, Loss: 2.9658, Exp_loss : 2.4131, Clip_loss ; 0.5527\n",
      "Step 16, Loss: 2.9775, Exp_loss : 2.4538, Clip_loss ; 0.5237\n",
      "Step 17, Loss: 3.0069, Exp_loss : 2.4382, Clip_loss ; 0.5686\n",
      "Step 18, Loss: 3.0658, Exp_loss : 2.4049, Clip_loss ; 0.6609\n",
      "Step 19, Loss: 3.0032, Exp_loss : 2.4106, Clip_loss ; 0.5926\n",
      "Step 20, Loss: 2.9238, Exp_loss : 2.4093, Clip_loss ; 0.5146\n",
      "Step 21, Loss: 3.0255, Exp_loss : 2.4158, Clip_loss ; 0.6097\n",
      "Step 22, Loss: 2.9308, Exp_loss : 2.3683, Clip_loss ; 0.5625\n",
      "Step 23, Loss: 2.9480, Exp_loss : 2.4122, Clip_loss ; 0.5358\n",
      "Step 24, Loss: 2.9777, Exp_loss : 2.3755, Clip_loss ; 0.6022\n",
      "Step 25, Loss: 2.9636, Exp_loss : 2.3773, Clip_loss ; 0.5863\n",
      "Step 26, Loss: 2.9263, Exp_loss : 2.4123, Clip_loss ; 0.5140\n",
      "Step 27, Loss: 3.0956, Exp_loss : 2.4133, Clip_loss ; 0.6824\n",
      "Step 28, Loss: 2.8743, Exp_loss : 2.3386, Clip_loss ; 0.5357\n",
      "Step 29, Loss: 2.9779, Exp_loss : 2.4043, Clip_loss ; 0.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 30, Loss: 2.9867, Exp_loss : 2.4012, Clip_loss ; 0.5854\n",
      "Finished Training\n",
      "model evaluation================================================================================\n",
      "avg total loss:2.9696, avg exp loss:2.4418, avg_clip_loss:0.5279\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pretrain_loss = loss.pretrain_loss()\n",
    "\n",
    "my_model = train.train_multi_epoch(my_model, \n",
    "                train_loader,\n",
    "                test_loader,\n",
    "                pretrain_loss, \n",
    "                #optimizer = optim.SGD(my_model.parameters(), lr=1e-4, momentum=0.9),\n",
    "               optimizer = optim.Adam(my_model.parameters(), lr = 5e-5, weight_decay=0.01),\n",
    "                device = 'cuda',\n",
    "                gradient_accumulation_steps = 24,\n",
    "                save_steps = 100,\n",
    "                save_dir = 'test_1',\n",
    "                epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3f0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12.1",
   "language": "python",
   "name": "torch1.12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
